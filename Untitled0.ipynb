{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMO1uBrIBPqwW6wp2aoM2PR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Working with different transformation and actions on RDD by fetching data from an external file\n"],"metadata":{"id":"9VeFRHXyRIAD"}},{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bwXUWX7UplQ","executionInfo":{"status":"ok","timestamp":1741146941088,"user_tz":-330,"elapsed":6468,"user":{"displayName":"Uday Singh","userId":"02796870780303216464"}},"outputId":"dbe16f82-42ab-43f3-a69c-ef1ebcc0aee6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"wOa7cAWGRGml","executionInfo":{"status":"ok","timestamp":1741146941685,"user_tz":-330,"elapsed":599,"user":{"displayName":"Uday Singh","userId":"02796870780303216464"}}},"outputs":[],"source":["from pyspark.context import SparkContext\n","from pyspark.sql import SparkSession"]},{"cell_type":"code","source":["spark = SparkSession.builder.appName('Spark1').getOrCreate()"],"metadata":{"id":"gSQQq-3gURMY","executionInfo":{"status":"ok","timestamp":1741146954174,"user_tz":-330,"elapsed":12487,"user":{"displayName":"Uday Singh","userId":"02796870780303216464"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["sc = SparkContext(\"local\",'iris')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"CIdB192KRXqq","executionInfo":{"status":"error","timestamp":1741146969843,"user_tz":-330,"elapsed":31,"user":{"displayName":"Uday Singh","userId":"02796870780303216464"}},"outputId":"f2cf8db7-5648-4bdc-d320-3f9b27cafb9e"},"execution_count":6,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Cannot run multiple SparkContexts at once; existing SparkContext(app=Spark1, master=local[*]) created by getOrCreate at <ipython-input-3-71910314c3c7>:1 ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-954ddde3d45f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'iris'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    199\u001b[0m             )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             self._do_init(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Raise error if there is already a running Spark context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    450\u001b[0m                         \u001b[0;34m\"Cannot run multiple SparkContexts at once; \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                         \u001b[0;34m\"existing SparkContext(app=%s, master=%s)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=Spark1, master=local[*]) created by getOrCreate at <ipython-input-3-71910314c3c7>:1 "]}]},{"cell_type":"code","source":["iris1 = sc.textFile('iris.csv',2)\n","iris1.collect()"],"metadata":{"id":"DDWRXFYoTEJa","executionInfo":{"status":"aborted","timestamp":1741146954294,"user_tz":-330,"elapsed":10,"user":{"displayName":"Uday Singh","userId":"02796870780303216464"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sc.stop()"],"metadata":{"id":"elHPEwKmYpiq","executionInfo":{"status":"aborted","timestamp":1741146954304,"user_tz":-330,"elapsed":1,"user":{"displayName":"Uday Singh","userId":"02796870780303216464"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pdoZvaPgbrX-"},"execution_count":null,"outputs":[]}]}